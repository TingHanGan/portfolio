---
title: "Performing Various Classification Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Task

**The data is obtained from <https://www.kaggle.com/jsphyg/weather-dataset-rattle-package>. The aim of the task was to predict next-day rain in Australia, but predicting whether or not the following day will be cloudy**\doublespacing

*The data contained multiple attributes and a class attribute "CloudTomorrow"*\doublespacing

*Pre-processing was required to make the data set suitable for the model. Within this project, there were 5 classification models used to precict "cloudiness" to then calculate the confidence of each case by producing an ROC curve for each classifier.*\doublespacing 

*There were also attempts at creating a decision tree by hand while also touching on Aritifical Neural Network classifiers and how it would perform within this dataset*\doublespacing 

Full report can be found on my github (private): <https://github.com/TingHanGan/FIT3152_Assignment2>.

```{r code, echo=FALSE}
rm(list = ls()) 
WAUS <- read.csv("CloudPredict2021.csv")
L <- as.data.frame(c(1:49))
set.seed(30583349)
L <- L[sample(nrow(L), 10, replace = FALSE),] # sample 10 locations
WAUS <- WAUS[(WAUS$Location %in% L),] 
WAUS <- WAUS[sample(nrow(WAUS), 2000, replace = FALSE),] #sample 2000 rows
attach(WAUS)

# Question 1 ________________
# What is the proportion of cloudy days to clear days? 
# 1 = Cloudy, 0 = Not-cloudy 
prop = rbind(length(which(WAUS$CloudTomorrow == 1)), length(which(WAUS$CloudTomorrow == 0)))
rownames(prop) = c("Cloudy (1)", "Not-cloudy (0)")
colnames(prop) = "No. of days"

# Data Cleaning ********

# Removing rows that have the target variable NA
WAUS = WAUS[!is.na(WAUS$CloudTomorrow),]

#https://stackoverflow.com/questions/9322773/how-to-replace-na-with-mean-by-group-subset
for (i in which(sapply(WAUS, is.numeric))) {
  for (j in which(is.na(WAUS[, i]))) {
    WAUS[j, i] <- mean(WAUS[WAUS[, "Location"] == WAUS[j, "Location"], i],  na.rm = TRUE)
  }
}

# Repalce missing categorical variable cells with the most frequent in each location 
# Adapted from code above
for (i in which(sapply(WAUS, is.factor))) {
  for (j in which(is.na(WAUS[, i]))) {
    WAUS[j, i] <- names(which.max(table(WAUS[WAUS[, "Location"] == WAUS[j, "Location"], i])))
  }
}

# Since location 30 did not have any values for the evaporation section
# we repalce it with the average value of the whole evaporation column 
WAUS$Evaporation[is.nan(WAUS$Evaporation)] <- mean(WAUS$Evaporation, na.rm = TRUE)


# creating a new dataframe with real attributes only 
real_attributes = WAUS[c(2,5:9,11,14:21)]

# descriptions of the predictor variables for real-valued attributes 
descrip = cbind(sapply(real_attributes, max), sapply(real_attributes, min), 
                round(sapply(real_attributes, mean), 2), round(sapply(real_attributes, median), 2), round(sapply(real_attributes, sd), 2))
colnames(descrip) = c("Max", "Min", "Mean", "Median", "SD")

# Omitting Day & Year from dataset
WAUS = WAUS[,-c(1,3)]

# Change the target variable (CloudTomorrow) to a factor variable 
WAUS$CloudTomorrow[WAUS$CloudTomorrow == 1] = "Cloudy"
WAUS$CloudTomorrow[WAUS$CloudTomorrow == 0] = "Clear"

WAUS$CloudTomorrow <- as.factor(WAUS$CloudTomorrow)

# Question 3 ________________
# Divide data into 70% training and 30% test
set.seed(30583349) # Student ID as random seed
train.row = sample(1:nrow(WAUS), 0.7*nrow(WAUS))
WAUS.train = WAUS[train.row,]
WAUS.test = WAUS[-train.row,]

# Question 4 ________________
# Decision Tree *****
library(tree)
WAUStree = tree(CloudTomorrow ~., data = WAUS.train)

# Naïve Bayes *****
library(e1071)
WAUSbayes = naiveBayes(CloudTomorrow ~., data = WAUS.train)

# Bagging *****
library(data.table)
library(caret)
library(adabag)
library(rpart)

WAUSbag = bagging(CloudTomorrow ~., data = WAUS.train, mfinal = 10)

# Boosting  *****
WAUSboost = boosting(CloudTomorrow ~., data = WAUS.train, mfinal = 10)

# Random Forest  *****
library(randomForest)
WAUSrf = randomForest(CloudTomorrow ~., data = WAUS.train)

# Question 5 ________________
# Decision Tree (Testing)
tpredict = predict(WAUStree, WAUS.test, type = "class")

# Naïve Bayes (Testing)
nbpredict = predict(WAUSbayes, WAUS.test)

# Bagging (Testing)
bpredict = predict.bagging(WAUSbag, newdata = WAUS.test)
bag.table = table(observed = WAUS.test$CloudTomorrow, predicted = bpredict$class)

# Boosting (Testing)
bopredict = predict.boosting(WAUSboost, newdata = WAUS.test)
boost.table = table(observed = WAUS.test$CloudTomorrow, predicted = bopredict$class)

# Random Forest (Testing)
rfpredict = predict(WAUSrf, WAUS.test)

# Question 6 ________________
library(ROCR)
# labels are actual values, predictors are probability of class
# Decision Tree ROC
tpred = predict(WAUStree, WAUS.test, type = "vector")
treepred = prediction(tpred[,2], WAUS.test$CloudTomorrow)
treeperf = performance(treepred, "tpr", "fpr")
treeauc = performance(treepred, "auc")

# Naïve Bayes ROC
bayespred = predict(WAUSbayes, WAUS.test, type = "raw")
nbpred = prediction(bayespred[,2], WAUS.test$CloudTomorrow)
nbperf = performance(nbpred, "tpr", "fpr")
nbauc = performance(nbpred, "auc")

# Bagging ROC
bagpred = prediction(bpredict$prob[,2], WAUS.test$CloudTomorrow)
bagperf = performance(bagpred, "tpr", "fpr")
bagauc = performance(bagpred, "auc")

# Boosting ROC 
boopred = prediction(bopredict$prob[,2], WAUS.test$CloudTomorrow)
booperf = performance(boopred, "tpr", "fpr")
booauc = performance(boopred, "auc")

# Random Forest ROC 
rfpred = predict(WAUSrf, WAUS.test, type = "prob")
randpred = prediction(rfpred[,2], WAUS.test$CloudTomorrow)
randperf = performance(randpred, "tpr", "fpr")
randauc = performance(randpred, "auc")

```

## Result

```{r plot, echo=FALSE}
# ROC Plot 
plot(treeperf, col = "red")
plot(nbperf, add = TRUE, col = "blue")
plot(bagperf, add = TRUE, col = "green3")
plot(booperf, add = TRUE, col = "orange")
plot(randperf, add = TRUE, col = "cyan")
abline(0,1, lty = 2)
title("ROC Curve for Each Classifier")
legend(0, 1.02, c("Decision Tree", "Naïve Bayes", "Bagging", "Boosting", "Random Forest", "Reference Line"),
       lty = c(1,1,1,1,1, 2), col = c("red", "blue", "green3", "orange", "cyan", "black"), cex = 0.75)

model.auc = rbind(treeauc@y.values, nbauc@y.values, bagauc@y.values, booauc@y.values, randauc@y.values) 
rownames(model.auc) = c("Decision Tree", "Naïve Bayes", "Bagging", "Boosting", "Random Forest")
colnames(model.auc) = "AUC (%)"
model.auc
```

By producing an ROC curve for each classifier and a corresponding AUC table, we are able to quickly identify which classifier would perform the best on average. Thus, it is seen here that Random Forest would be the best classifier in this case. 
